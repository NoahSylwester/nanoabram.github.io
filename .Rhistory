select(-c(time, subject, rep))
french_fries$treatment <- ifelse(french_fries$treatment == 1, "Peanut", ifelse(french_fries$treatment == 2, "Canola", "Grapeseed"))
french_fries$treatment <- as.factor(french_fries$treatment)
# Check the data set for missing data and remove rows that are missing any values
french_fries %>% mutate_all(na_if,"") %>% visdat::vis_miss()
# Partition the data so that 70% of the original data set goes into a training model and 30% goes into a testing model
partition_data_fries <- createDataPartition(french_fries$treatment, times = 1, p = .7, list = FALSE)
training.set <- french_fries[partition_data_fries, ] # Training set
testing.set <- french_fries[-partition_data_fries, ] # Testing set
# Resample the data with k-Fold Cross Validation
train.control <- trainControl(method = "cv", number = 10) # k-folds CV with k=10
# Try to find the best model angain and use the tuning grid appropriate for the model you choose.
#including an action to exclude na, one of which is being introduced somehow
fry.model <- train(treatment ~ .,
data = training.set,
method = "rf",
trControl = train.control,
preProc = c("center"),
na.action="na.exclude")
treebag.fry.model <- train(treatment ~ .,
data = training.set,
method = "treebag",
trControl = train.control,
preProc = c("center"),
na.action="na.exclude")
# Create a dataset of predicted values using the predict function
fry.predict <- predict(fry.model, testing.set)
treebag.fry.predict <- predict(treebag.fry.model, testing.set)
# Evaluate how accurate your predicted data is at determining what type of oil the french fries were fried in compared to the test set of the original data
#taking out values from testing set to account for the na value we removed earlier, seems to be a little random so I've robustly indexed
postResample(fry.predict, testing.set$treatment[1:length(fry.predict)])
postResample(treebag.fry.predict, testing.set$treatment[1:length(fry.predict)])
#treebag seems to win again, though neither of them ever do much better than 33%, which I would expect to be the rate at which random guessing would work
library(tidyverse)
library(rvest)
library(dplyr)
library(stringr)
library(tidyr)
library(ggplot2)
# Knit options
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(rvest)
read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table")
library(dplyr)
library(rvest)
read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table()
library(dplyr)
library(rvest)
read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
table_list[5:6]
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
rbind(table_list[5:6])
?rbind
?rbind
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
rbindlist(table_list[5:6])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
rbind_list(table_list[5:6])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
bind_rows(table_list[5:6])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
table_list[5][1,]
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
table_list[5][[1,]]
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
table_list[5]
#bind_rows(table_list[5:6])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
table_list[5][-1]
#bind_rows(table_list[5:6])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
str(table_list[5])
#bind_rows(table_list[5:6])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
table_list[[5]][1,]
#bind_rows(table_list[5:6])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
bind_rows(table_list[[5:6]])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
bind_rows(table_list[5:6])
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
str(bind_rows(table_list[5:6]))
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
select(X1 != "State")
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
US_bf
library(dplyr)
library(rvest)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.numeric(format(MostRecentReport, "%m-%Y")))
?format
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.numeric(format(MostRecentReport, format = "%m-%Y")))
as.numeric(format(US_bf$MostRecentReport, format = "%m-%Y")))
as.numeric(format(US_bf$MostRecentReport, format = "%m-%Y"))
?as.Date
as.Date(US_bf$MostRecentReport, format = "%m-%Y")
as.date(US_bf$MostRecentReport, format = "%m-%Y")
as.Date(x = US_bf$MostRecentReport, format = "%m-%Y")
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.Date(x = MostRecentReport, tryFormats = "%m-%Y")
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.Date(x = MostRecentReport, format = "%m-%Y")
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.Date(MostRecentReport, format = "%m-%Y")
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.Date(x = MostRecentReport, format = "%m-%Y"))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.Date(x = MostRecentReport, tryFormats = "%m-%Y"))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.Date(MostRecentReport, format = "%m-%Y"))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.Date(MostRecentReport, format = "%m-%Y"))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = as.Date(format(MostRecentReport, format = "%m-%Y")))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, format = "mY"))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY"))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY")) %>%
arrange(desc(MostRecentReport), '# ofListings')
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY")) %>%
arrange(desc(MostRecentReport), `# ofListings`)
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
# parsing month-years as dates, assuming day 1 of month
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY")) %>%
arrange(desc(MostRecentReport), desc(`# ofListings`))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
# parsing month-years as dates, assuming day 1 of month
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY")) %>%
arrange(desc(MostRecentReport), desc(as.numeric(`# ofListings`)))
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
# parsing month-years as dates, assuming day 1 of month
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY")) %>%
arrange(desc(MostRecentReport), desc(as.numeric(`# ofListings`)))
#Probably Washington is the most squatch
read_html("http://www.bfro.net/GDB/state_listing.asp?state=or") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
read_html("http://www.bfro.net/GDB/state_listing.asp?state=or") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
OR_table_list <- read_html("http://www.bfro.net/GDB/state_listing.asp?state=or") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
OR_names <- OR_table_list[[7]][1,]
OR_bf <- bind_rows(OR_table_list[7:8]) %>%
filter(X1 != "County")
colnames(US_bf) <- OR_names
# parsing month-years as dates, assuming day 1 of month
OR_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY")) %>%
arrange(desc(MostRecentReport), desc(as.numeric(`# ofListings`)))
OR_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY"))
OR_bf
library(dplyr)
library(rvest)
library(lubridate)
table_list <- read_html("https://www.bfro.net/GDB/") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
names <- table_list[[5]][1,]
US_bf <- bind_rows(table_list[5:6]) %>%
filter(X1 != "State")
colnames(US_bf) <- names
# parsing month-years as dates, assuming day 1 of month
US_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY")) %>%
arrange(desc(MostRecentReport), desc(as.numeric(`# ofListings`)))
#Probably Washington is the most squatch
OR_table_list <- read_html("http://www.bfro.net/GDB/state_listing.asp?state=or") %>%
html_nodes("table") %>%
html_table(fill = TRUE)
OR_names <- OR_table_list[[7]][1,]
OR_bf <- bind_rows(OR_table_list[7:8]) %>%
filter(X1 != "County")
colnames(OR_bf) <- OR_names
# parsing month-years as dates, assuming day 1 of month
OR_bf %>%
mutate(MostRecentReport = parse_date_time(MostRecentReport, "mY"), LastPosted = parse_date_time(LastPosted, "mY")) %>%
arrange(desc(MostRecentReport), desc(as.numeric(`# ofListings`)))
read_html("https://www.imdb.com/title/tt4154796/plotsummary?ref_=tt_stry_pl") %>%
html_nodes("ul li") %>%
html_text()
read_html("https://www.imdb.com/title/tt4154796/plotsummary?ref_=tt_stry_pl") %>%
html_nodes("#synopsis-py4495824") %>%
html_text()
avengers_plot <- read_html("https://www.imdb.com/title/tt4154796/plotsummary?ref_=tt_stry_pl") %>%
html_nodes("#synopsis-py4495824") %>%
html_text()
library(tidytext)
unnest_tokens(avengers_plot)
?unnest_tokens
unnest_tokens(as.data.frame(avengers_plot), token = "words")
unnest_tokens(vector(avengers_plot), token = "words")
unnest_tokens(input = avengers_plot, token = "words")
unnest_tokens(as.data.frame(text = avengers_plot), token = "words")
unnest_tokens(as.data.frame(avengers_plot), token = "words")
unnest_tokens(as.data.frame(x = c(text = avengers_plot)), token = "words")
?as.data.frame
as.data.frame(x=avengers_plot, col.names = "text")
avengers_plot
avengers_plot
as.data.frame(x=c(text=avengers_plot), col.names = "text")
as.data.frame(x=c(text=avengers_plot))
as.data.frame(avengers_plot)
data.frame(avengers_plot)
data.frame(c("text" = avengers_plot))
str(data.frame(c("text" = avengers_plot)))
str(data.frame(avengers_plot))
unnest_tokens(data.frame(avengers_plot), token = "words")
avengers_plot <- read_html("https://www.imdb.com/title/tt4154796/plotsummary?ref_=tt_stry_pl") %>%
html_nodes("#synopsis-py4495824") %>%
html_text()
library(tidytext)
unnest_tokens(data.frame(avengers_plot, stringsAsFactors = FALSE), token = "words")
?unnest_tokens
unnest_tokens(data.frame(avengers_plot, stringsAsFactors = FALSE), word, text)
unnest_tokens(data.frame(avengers_plot, stringsAsFactors = FALSE), word, avengers_plot)
lot_words <- unnest_tokens(data.frame(avengers_plot, stringsAsFactors = FALSE), word, avengers_plot) %>%
anti_join(stop_words) %>%
count(word)
View(lot_words)
View(lot_words)
View(lot_words)
plot_words <- unnest_tokens(data.frame(avengers_plot, stringsAsFactors = FALSE), word, avengers_plot) %>%
anti_join(stop_words) %>%
count(word) %>%
arrange(desc(n))
View(plot_words)
?wordcloud
library(wordcloud)
plot_words %>%
filter(n >= 3) %>%
with(wordcloud(word, n, max.words = 100))
plot_words %>%
filter(n >= 4) %>%
with(wordcloud(word, n, max.words = 100))
serve_site()
blogdown::serve_site()
